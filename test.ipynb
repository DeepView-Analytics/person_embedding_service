{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"C:\\Users\\Asus/.cache\\torch\\checkpoints\\osnet_x1_0_imagenet.pth\"\n",
      "Successfully loaded pretrained weights from \"osnet_x1_0_imagenet.pth\"\n",
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Feature Embeddings Shape: (16, 512)\n",
      "Feature Embeddings: [[1.6604468  4.0208244  0.57321197 ... 0.         0.6829157  0.        ]\n",
      " [0.8958622  3.2568913  0.         ... 0.         0.19255444 0.        ]\n",
      " [1.6604468  4.0208244  0.57321197 ... 0.         0.6829157  0.        ]\n",
      " ...\n",
      " [0.8958622  3.2568913  0.         ... 0.         0.19255444 0.        ]\n",
      " [1.6604468  4.0208244  0.57321197 ... 0.         0.6829157  0.        ]\n",
      " [0.8958622  3.2568913  0.         ... 0.         0.19255444 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchreid.utils import load_pretrained_weights\n",
    "from torchreid.models import build_model\n",
    "from torchreid.data.transforms import build_transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model and transformations globally to avoid re-initializing them for each function call\n",
    "model = build_model(name='osnet_x1_0', num_classes=1000)\n",
    "load_pretrained_weights(model, 'osnet_x1_0_imagenet.pth')\n",
    "model.eval()\n",
    "_, transform = build_transforms(height=256, width=128)\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from a file path.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return img\n",
    "\n",
    "def process_batch(image_paths):\n",
    "    \"\"\"Process a batch of images and return their feature embeddings.\"\"\"\n",
    "    batch_images = []\n",
    "    for image_path in image_paths:\n",
    "        img = load_image(image_path)\n",
    "        img_transformed = transform(img)\n",
    "        batch_images.append(img_transformed)\n",
    "\n",
    "    # Convert list of tensors to a single tensor with batch dimension\n",
    "    batch_images_tensor = torch.stack(batch_images)\n",
    "\n",
    "    # Run the batch through the model to get feature embeddings\n",
    "    with torch.no_grad():\n",
    "        features = model(batch_images_tensor)\n",
    "    \n",
    "    # Convert the features to a numpy array for easier handling\n",
    "    features_np = features.cpu().numpy()\n",
    "    return features_np\n",
    "\n",
    "# Example usage\n",
    "image_paths = [\n",
    "    r'D:\\DeepView\\MicroServices\\person_embedding\\saru.jpg',\n",
    "    r'D:\\DeepView\\MicroServices\\person_embedding\\1.jpg'\n",
    "]\n",
    "\n",
    "embeddings = process_batch(image_paths)\n",
    "print(\"Feature Embeddings Shape:\", embeddings.shape)\n",
    "print(\"Feature Embeddings:\", embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
